# **Project Overview** ##
This section contains a Jupyter Notebook that takes in a CSV file containing mock data from a car delaership. The data contains customer salary, age, and whether or not they purchased the vehicle. Finding the best classification model will help target future customers through social network ads. 

---
## [Table of Contents](#Classification-Models)
- [01 - Logistic Regression](#01---Logistic-Regression)
- [02 - K-Nearest Regression](#02---K-Nearest-Regression)
- [03 - Support Vector Machine](#03---Support-Vector-Machine)
- [04 - Kernel SVM](#04---Kernel-SVM)
- [05 - Naive Bayes](#05---Naive-Bayes)

## Classification Template Files 
- 

---
## **Classification Models**
### **[01 - Logistic Regression](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/01-logistic-regression/logistic_regression.ipynb)**
#### **Getting Started** 
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
```   
#### **Section Overview**
This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset using the **scikit-learn** module (**LogisticRegression**)
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module

#### **Logistic Regression Model**
![Logistic Regression](/classification/01-logistic-regression/logistic_regression.png)

---
### **[02 - K-Nearest Regression](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/02-k-nearest/k_nearest_regression.ipynb)**


#### **Getting Started**   
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
```   
#### **Section Overview**
This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset using the **scikit-learn** module (**KNeighborsClassifier**)
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module

#### **K-Nearest Regression Model**
![K-Nearest Regression](/classification/02-k-nearest/k_nearest_regression.png)

---


### **[03 - Support Vector Machine](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/03-support-vector-machine/support_vector_machine.ipynb)**
#### **Getting Started**   
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
```   
#### **Section Overview**
This section contains a Jupyter Notebook that takes in a CSV file a dataset of previous customer info from a popular car dealership. We want to determine if a customer will purchase a new vehicle based on age and salary.

This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset using the **scikit-learn** module (**SVC**)
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module

#### **Support Vector Machine Model**
![Support Vector Machine](/classification/03-support-vector-machine/support_vector_machine.png)

---

### **[04 - Kernel SVM](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/04-kernel-svm/kernel_svm.ipynb)**

#### **Getting Started** 
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
```   
#### **Section Overview**
This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset using the **scikit-learn** module (**SVC**)
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module

#### **Kernel SVM Model**
![Kernel SVM](/classification/04-kernel-svm/kernel_svm.png)

---


### **[05 - Naive Bayes](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/04-naive-bayes/naive_bayes.ipynb)**

#### **Getting Started** 
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
``` 

#### **Section Overview**
This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset on Naive Bayes using the **scikit-learn** module (**GaussianNB**)
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module

#### **Naive Bayes Model**
![Naive Bayes](/classification/05-naive-bayes/naive_bayes.png)

---

### **[06 - Decision Tree Classification](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/06-decision-tree-classification/decision_tree_classification.ipynb)**

#### **Getting Started** 
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
``` 
#### **Section Overview**
This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset on Naive Bayes using the **scikit-learn** module **DecisionTreeClassifier**
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module

#### **Decision Tree Classification**
![Decision Tree Classification](/classification/06-decision-tree-classification/decision_tree_classification.png)

---

### **[07 - Random Forest Classification](https://github.com/jerrvonewing/machine-learning-a-to-z/blob/main/classification/07-random-forest-classification/random_forest_classification.ipynb)**

#### **Getting Started** 
This section is written using a Jupyter framework, where all packages are installed in  Google Collab. If you need to install the packages used in this section, copy the following commands:

```powershell
pip install numpy
pip install matplotlib
pip install pandas
pip install scikit-learn
``` 
#### **Section Overview**
This section demonstrates:

- Reading data from a CSV file using **pandas**
- Training the dataset on Naive Bayes using the **scikit-learn** module **RandomForestClassifier**
- Splitting the data into training and test sets using **train_test_split** from the **scikit-learn** module
- Feature Scaling using and Standardization using **StandardScaler** from the **scikit-learn** module
- Creation of a **confusion matrix** and calulating the accuracy score
- Predicting single and multiple values
- Visualization the data using the **matplotlib** module


#### **Support Vector Machine Model**
![07 - Random Forest Classification](/classification/07-random-forest-classification/random_forest_classification.png)

